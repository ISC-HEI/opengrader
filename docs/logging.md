# OpenGrader Logging

OpenGrader includes comprehensive logging to help you understand what's happening during grading sessions, including thought signatures from Gemini 3 models.

## Overview

The logging system captures:
- **Thought Signatures**: Encrypted representations of the model's internal reasoning (Gemini 3 feature)
- **Model Responses**: All content generated by the AI model
- **Tool Calls**: Every tool/skill invocation with arguments
- **Agent State**: Internal agent state transitions and message flow
- **Errors**: Detailed error information with stack traces

## Log Files

Log files are automatically created in the `logs/` directory with timestamps:

```
logs/
  opengrader_20260206_143022.log
  opengrader_20260206_150134.log
  ...
```

Each session creates a new log file with format: `opengrader_YYYYMMDD_HHMMSS.log`

## Log Levels

### Console Output (INFO level)
The console shows high-level information:
- User messages
- Agent responses (truncated)
- Tool call names
- Thought signature previews (first 100 chars)

### File Output (DEBUG level)
The log file contains everything:
- Full message content
- Complete thought signatures
- Detailed tool arguments (JSON formatted)
- Agent state transitions
- All messages in conversation history
- Stack traces for errors

## What Are Thought Signatures?

Thought signatures are a Gemini 3 feature that represents the model's internal reasoning process in encrypted form. They are essential for:

1. **Multi-turn Conversations**: Maintaining context across multiple exchanges
2. **Function Calling**: Preserving reasoning when the model calls tools/skills
3. **Context Preservation**: Ensuring the model remembers its previous reasoning steps

### How LiteLLM Handles Thought Signatures

According to the [LiteLLM documentation](https://docs.litellm.ai/blog/gemini_3):

1. **Automatic Extraction**: When Gemini 3 returns a function call, LiteLLM automatically extracts the `thought_signature`
2. **Storage**: Thought signatures are stored in `provider_specific_fields.thought_signature` of tool calls
3. **Automatic Preservation**: When you include the assistant's message in conversation history, LiteLLM automatically preserves and returns thought signatures to Gemini

OpenGrader logs these thought signatures so you can:
- Debug conversation flow issues
- Understand when context is being preserved
- Troubleshoot multi-turn function calling

## Example Log Output

### Console Output
```
INFO - User message (thread: demo): What files do I have?
INFO - Tool call 0: inventory_skill
INFO - Thought signature (preview): CpcHAdHtim9+q4rstcbvQC0ic4x1/vqQlCJWgE+UZ6dTLYGHMMBkF/AxqL5UmP6SY46uYC8t4BTFiXG5zkw6EMJ...
INFO - Agent response: I found the following files in your working directory...
```

### File Output (DEBUG)
```
2026-02-06 14:30:22 - OpenGrader - INFO - ================================================================================
2026-02-06 14:30:22 - OpenGrader - INFO - User message (thread: demo): What files do I have?
2026-02-06 14:30:22 - OpenGrader - INFO - ================================================================================
2026-02-06 14:30:22 - OpenGrader - DEBUG - Full message with context: You are OpenGrader, an AI assistant...
2026-02-06 14:30:23 - OpenGrader - DEBUG - Agent invocation completed
2026-02-06 14:30:23 - OpenGrader - DEBUG - Agent returned 2 messages
2026-02-06 14:30:23 - OpenGrader - DEBUG - Message 0 type: HumanMessage
2026-02-06 14:30:23 - OpenGrader - DEBUG - Message 1 type: AIMessage
2026-02-06 14:30:23 - OpenGrader - DEBUG - Tool calls found in response (choice 0)
2026-02-06 14:30:23 - OpenGrader - INFO - Tool call 0: inventory_skill
2026-02-06 14:30:23 - OpenGrader - INFO - Thought signature (preview): CpcHAdHtim9+q4rstcbvQC0ic4x1/vqQlCJWgE+UZ6dTLYGHMMBkF/AxqL5UmP6SY46uYC8t4BTFiXG5zkw6EMJ...
2026-02-06 14:30:23 - OpenGrader - DEBUG - Full thought signature: CpcHAdHtim9+q4rstcbvQC0ic4x1/vqQlCJWgE+UZ6dTLYGHMMBkF/AxqL5UmP6SY46uYC8t4BTFiXG5zkw6EMJhkjsdfkljsdfkljsdflkjsdflkjsdf...
2026-02-06 14:30:23 - OpenGrader - DEBUG - Tool arguments: {
  "working_dir": "/path/to/exams"
}
2026-02-06 14:30:23 - OpenGrader - INFO - Model response content: I found the following files in your working directory...
2026-02-06 14:30:23 - OpenGrader - DEBUG - Full model response: I found the following files in your working directory:\n\n1. questions.md\n2. answers/student1.pdf\n...
```

## Configuration

### Custom Log Directory

You can specify a custom log directory when initializing the agent:

```python
from grader_agent2 import OpenGraderAgent

agent = OpenGraderAgent(
    working_dir="./my_exams",
    log_dir="./custom_logs"  # Custom log directory
)
```

### Adjusting Log Levels

To change log levels programmatically:

```python
import logging

# Get the OpenGrader logger
logger = logging.getLogger("OpenGrader")

# Change console output to DEBUG (very verbose)
for handler in logger.handlers:
    if isinstance(handler, logging.StreamHandler):
        handler.setLevel(logging.DEBUG)

# Or reduce console output to WARNING (quiet)
for handler in logger.handlers:
    if isinstance(handler, logging.StreamHandler):
        handler.setLevel(logging.WARNING)
```

## Troubleshooting with Logs

### Missing Thought Signatures

If you don't see thought signatures in the logs:
1. Verify you're using Gemini 3 model (`gemini/gemini-3-flash-preview` or `gemini/gemini-3-pro-preview`)
2. Check that the model is actually making function calls (thought signatures only appear with tool calls)
3. Ensure LiteLLM is up to date

### Understanding Multi-turn Conversations

When debugging multi-turn conversations:
1. Look for thought signatures in each turn
2. Verify they're being preserved across turns
3. Check that tool results are being properly returned to the model

### Performance Issues

If you notice performance issues:
1. Check log file size (they can grow large with DEBUG level)
2. Consider rotating log files or reducing retention
3. The logging overhead is minimal but file I/O can add latency

## Best Practices

1. **Keep Logs for Debugging**: Don't delete logs immediately - they're invaluable for debugging
2. **Review After Issues**: When something goes wrong, check the log file first
3. **Monitor Thought Signatures**: If multi-turn conversations fail, verify thought signatures are present
4. **Use Log Levels Appropriately**: 
   - Development: DEBUG level in files
   - Production: INFO level in files, WARNING on console
5. **Rotate Logs**: Implement log rotation for long-running systems

## Example Usage

See `example_with_logging.py` for a complete example:

```bash
python example_with_logging.py
```

This will:
1. Create a new log file in `logs/`
2. Start an interactive grading session
3. Log all activity including thought signatures
4. Show you where to find the detailed logs

## Related Documentation

- [LiteLLM Gemini 3 Documentation](https://docs.litellm.ai/blog/gemini_3)
- [Thought Signatures Guide](https://docs.litellm.ai/blog/gemini_3#thought-signatures)
- [OpenGrader README](../README.md)
